# API env
PORT=3001
DATABASE_URL=postgres://postgres:postgres@localhost:5432/notion_ai
GEMINI_API_KEY=

# LLM provider for text generation: gemini | ollama
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_MODEL=qwen2.5:7b-instruct

# If true, fallback to Gemini when Ollama fails
LLM_FALLBACK_TO_GEMINI=true
